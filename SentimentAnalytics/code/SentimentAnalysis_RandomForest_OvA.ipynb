{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abdd573",
   "metadata": {},
   "source": [
    "# SentimentAnalysis\n",
    "## Random Forest\n",
    "### [ Opiniones VS Atracciones ]\n",
    "#### Ing. Luis Felipe Narvaez Gomez. E-mail: luis.narvaez@usantoto.edu.co. Cod: 2312660. Facultad de Ingenieria de Sistemas. USTA.\n",
    "\n",
    "\n",
    "### Importar Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efcdfe0",
   "metadata": {},
   "source": [
    "Vamos ahora a importar los modelos que ya hemos realizado para la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10fbd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ruiso Local\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae92b0",
   "metadata": {},
   "source": [
    "### Leer un archivo XLSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a45422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo de tipo XLSX\n",
    "dfData = pd.read_excel(\"Rest_Mex_2022_Sentiment_Analysis_Track_Train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8cdc8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Opinion', 'Polarity', 'Attraction'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7b2cd",
   "metadata": {},
   "source": [
    "### Establecer FEATURES y LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d491c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0]       [1]         [2]        [3]\n",
    "# ['Title', 'Opinion', 'Polarity', 'Attraction']\n",
    "\n",
    "features = dfData.iloc[:,1].values  # Opinion\n",
    "labels = dfData.iloc[:,3].values    # Attraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a032e37",
   "metadata": {},
   "source": [
    "### Limpiar la Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e00cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features = []\n",
    "\n",
    "for sentence in range(0, len(features)):\n",
    "    #Remove all the special characters\n",
    "    processed_feature = re.sub(r'\\W',' ', str(features[sentence]))\n",
    "    #remove all single characters\n",
    "    processed_feature = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "    #remove single characters from the start\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "    #substituting multiple spaces with single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "    #removing prefixxed 'b'\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "    #converting to lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "    #a√±adirlo al arreglo alv\n",
    "    processed_features.append(processed_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887ab50",
   "metadata": {},
   "source": [
    "### StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219bb257",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer (max_features=2500, \n",
    "                              min_df = 7, \n",
    "                              max_df=0.8, \n",
    "                              stop_words=stopwords.words('spanish'))\n",
    "processed_features = vectorizer.fit_transform(processed_features).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f501b",
   "metadata": {},
   "source": [
    "### Vectores de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a0e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(processed_features, \n",
    "                                                    labels, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed585044",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecae0a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classifier = RandomForestClassifier(n_estimators=200, \n",
    "                                         random_state=0)\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e2a07",
   "metadata": {},
   "source": [
    "### Ahora a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e2f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions  =(text_classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de8d1e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1024    6   25]\n",
      " [  13 3170   65]\n",
      " [  14  100 1626]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892e3b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Attractive       0.97      0.97      0.97      1055\n",
      "       Hotel       0.97      0.98      0.97      3248\n",
      "  Restaurant       0.95      0.93      0.94      1740\n",
      "\n",
      "    accuracy                           0.96      6043\n",
      "   macro avg       0.96      0.96      0.96      6043\n",
      "weighted avg       0.96      0.96      0.96      6043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7459dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9630977991064041\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16725d7",
   "metadata": {},
   "source": [
    "### Exportar Modelo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07a861d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a exportar este modelo porque aja :v\n",
    "\n",
    "with open('SentimentAnalysis_RandomForest_OvA','wb') as picklefile:\n",
    "    pickle.dump(text_classifier, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce650f2",
   "metadata": {},
   "source": [
    "### Importar Modelo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "248f6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos llamar este modelo para despues porque aja :v\n",
    "\n",
    "with open('SentimentAnalysis_RandomForest_OvA','rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "113bb8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1024    6   25]\n",
      " [  13 3170   65]\n",
      " [  14  100 1626]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Attractive       0.97      0.97      0.97      1055\n",
      "       Hotel       0.97      0.98      0.97      3248\n",
      "  Restaurant       0.95      0.93      0.94      1740\n",
      "\n",
      "    accuracy                           0.96      6043\n",
      "   macro avg       0.96      0.96      0.96      6043\n",
      "weighted avg       0.96      0.96      0.96      6043\n",
      "\n",
      "0.9630977991064041\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a4ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
